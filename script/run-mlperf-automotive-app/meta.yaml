alias: run-mlperf-automotive-app
uid: 2a7315d2dff74898

automation_alias: script
automation_uid: 5b4e0237da074764

category: Modular MLPerf inference benchmark pipeline

developers: "[Arjun Suresh](https://www.linkedin.com/in/arjunsuresh), [Grigori Fursin](https://cKnowledge.org/gfursin)"


clean_output_files:
- open.tar.gz
- summary.csv
- summary.json

tags:
- run
- run-abtf
- run-abtf-inference
- mlcommons
- inference
- reference

tags_help: "run-abtf,inference"

default_env:
  MLC_MLPERF_IMPLEMENTATION: reference
  MLC_MLPERF_MODEL: retinanet
  MLC_MLPERF_RUN_STYLE: test

input_mapping:
  backend: MLC_MLPERF_BACKEND
  clean: MLC_MLPERF_CLEAN_ALL
  compliance: MLC_MLPERF_LOADGEN_COMPLIANCE
  dashboard_wb_project: MLC_MLPERF_DASHBOARD_WANDB_PROJECT
  dashboard_wb_user: MLC_MLPERF_DASHBOARD_WANDB_USER
  debug: MLC_DEBUG_SCRIPT_BENCHMARK_PROGRAM
  device: MLC_MLPERF_DEVICE
  division: MLC_MLPERF_SUBMISSION_DIVISION
  docker: MLC_MLPERF_USE_DOCKER
  dump_version_info: MLC_DUMP_VERSION_INFO
  save_console_log: MLC_SAVE_CONSOLE_LOG
  execution_mode: MLC_MLPERF_RUN_STYLE
  find_performance: MLC_MLPERF_FIND_PERFORMANCE_MODE
  framework: MLC_MLPERF_BACKEND
  gh_token: MLC_GH_TOKEN
  gpu_name: MLC_NVIDIA_GPU_NAME
  hw_name: MLC_HW_NAME
  hw_notes_extra: MLC_MLPERF_SUT_SW_NOTES_EXTRA
  imagenet_path: IMAGENET_PATH
  implementation: MLC_MLPERF_IMPLEMENTATION
  lang: MLC_MLPERF_IMPLEMENTATION
  mode: MLC_MLPERF_LOADGEN_MODE
  model: MLC_MLPERF_MODEL
  multistream_target_latency: MLC_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY
  offline_target_qps: MLC_MLPERF_LOADGEN_OFFLINE_TARGET_QPS
  output_dir: OUTPUT_BASE_DIR
  output_summary: MLPERF_INFERENCE_SUBMISSION_SUMMARY
  output_tar: MLPERF_INFERENCE_SUBMISSION_TAR_FILE
  performance_sample_count: MLC_MLPERF_LOADGEN_PERFORMANCE_SAMPLE_COUNT
  power: MLC_SYSTEM_POWER
  precision: MLC_MLPERF_MODEL_PRECISION
  preprocess_submission: MLC_RUN_MLPERF_SUBMISSION_PREPROCESSOR
  push_to_github: MLC_MLPERF_RESULT_PUSH_TO_GITHUB
  readme: MLC_MLPERF_README
  regenerate_accuracy_file: MLC_MLPERF_REGENERATE_ACCURACY_FILE
  regenerate_files: MLC_REGENERATE_MEASURE_FILES
  rerun: MLC_RERUN
  results_dir: OUTPUT_BASE_DIR
  results_git_url: MLC_MLPERF_RESULTS_GIT_REPO_URL
  run_checker: MLC_RUN_SUBMISSION_CHECKER
  run_style: MLC_MLPERF_RUN_STYLE
  scenario: MLC_MLPERF_LOADGEN_SCENARIO
  server_target_qps: MLC_MLPERF_LOADGEN_SERVER_TARGET_QPS
  singlestream_target_latency: MLC_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY
  skip_submission_generation: MLC_MLPERF_SKIP_SUBMISSION_GENERATION
  skip_truncation: MLC_SKIP_TRUNCATE_ACCURACY
  submission_dir: MLC_MLPERF_INFERENCE_SUBMISSION_DIR
  submitter: MLC_MLPERF_SUBMITTER
  sut_servers: MLC_NETWORK_LOADGEN_SUT_SERVERS
  sw_notes_extra: MLC_MLPERF_SUT_SW_NOTES_EXTRA
  system_type: MLC_MLPERF_SUBMISSION_SYSTEM_TYPE
  target_latency: MLC_MLPERF_LOADGEN_TARGET_LATENCY
  target_qps: MLC_MLPERF_LOADGEN_TARGET_QPS
  test_query_count: MLC_TEST_QUERY_COUNT
  threads: MLC_NUM_THREADS
  batch_size: MLC_MLPERF_LOADGEN_MAX_BATCHSIZE
  sut: MLC_MLPERF_INFERENCE_SUT_VARIATION

new_state_keys:
- app_mlperf_inference_*
- mlc-mlperf-inference-results*

deps:
- tags: detect,os
  skip_if_env:
    MLC_MLPERF_USE_DOCKER: [ on ]
- tags: detect,cpu
  skip_if_env:
    MLC_MLPERF_USE_DOCKER: [ on ]
- names:
  - python
  - python3
  tags: get,python3
  skip_if_env:
    MLC_MLPERF_USE_DOCKER: [ on ]
- names:
  - automotive-src
  tags: get,mlcommons,automotive,src
  skip_if_env:
    MLC_MLPERF_USE_DOCKER: [ on ]
- tags: get,sut,description
  skip_if_env:
    MLC_MLPERF_USE_DOCKER: [ on ]

- tags: get,mlperf,inference,results,dir
  names:
    - get-mlperf-inference-results-dir
  enable_if_env:
    MLC_MLPERF_USE_DOCKER: [ off ]
  skip_if_env:
    OUTPUT_BASE_DIR: [ on ]
- tags: install,pip-package,for-mlc-python,_package.tabulate
- tags: get,mlperf,automotive,utils
  skip_if_env:
    MLC_MLPERF_USE_DOCKER: [ on ]

variations:
  accuracy-only:
    default_variations:
      submission-generation-style: full
    env:
      MLC_MLPERF_LOADGEN_MODE: accuracy
      MLC_MLPERF_SUBMISSION_RUN: 'yes'
      MLC_RUN_MLPERF_ACCURACY: 'on'
      MLC_RUN_SUBMISSION_CHECKER: 'no'
    group: submission-generation

  all-modes:
    env:
      MLC_MLPERF_LOADGEN_ALL_MODES: 'yes'
    group: mode

  all-scenarios:
    env:
      MLC_MLPERF_LOADGEN_ALL_SCENARIOS: 'yes'

  compliance:
    env:
      MLC_MLPERF_LOADGEN_COMPLIANCE: 'yes'

  dashboard:
    default_gui: false
    env:
      MLC_MLPERF_DASHBOARD: 'on'

  find-performance:
    env:
      MLC_MLPERF_FIND_PERFORMANCE_MODE: 'yes'
      MLC_MLPERF_LOADGEN_ALL_MODES: 'no'
      MLC_MLPERF_LOADGEN_MODE: performance
      MLC_MLPERF_RESULT_PUSH_TO_GITHUB: false
    group: submission-generation

  full:
    add_deps_recursive:
      coco2014-original:
        tags: _full
      coco2014-preprocessed:
        tags: _full
    env:
      MLC_MLPERF_SUBMISSION_GENERATION_STYLE: full
      MLC_MLPERF_SKIP_SUBMISSION_GENERATION: 'yes'
    group: submission-generation-style

  performance-only:
    default_variations:
      submission-generation-style: full
    env:
      MLC_MLPERF_LOADGEN_MODE: performance
      MLC_MLPERF_SUBMISSION_RUN: 'yes'
      MLC_RUN_SUBMISSION_CHECKER: 'no'
    group: submission-generation

  mvp-demo:
    default_env:
      MLC_MLPERF_DEVICE: cpu

    env:
      MLC_MLPERF_INFERENCE_VERSION: mvp-demo
      MLC_MLPERF_MODEL: abtf-demo-model
      MLC_MLPERF_BACKEND: pytorch 
      MLC_MLPERF_IMPLEMENTATION: mlcommons-python
      MLC_MLPERF_LOADGEN_SCENARIO: SingleStream
      MLC_RUN_MLPERF_INFERENCE_APP_DEFAULTS: mvp-demo
    adr:
      compiler:
        tags: gcc
    group: benchmark-version

  poc-demo:
    default_env:
      MLC_MLPERF_DEVICE: cpu
      MLC_TEST_QUERY_COUNT: "20"

    env:
      MLC_MLPERF_INFERENCE_VERSION: poc-demo
      MLC_MLPERF_MODEL: abtf-poc-model
      MLC_MLPERF_BACKEND: pytorch
      MLC_MLPERF_IMPLEMENTATION: mlcommons-python
      MLC_MLPERF_LOADGEN_SCENARIO: SingleStream
      MLC_RUN_MLPERF_INFERENCE_APP_DEFAULTS: poc-demo
    adr:
      compiler:
        tags: gcc
    group: benchmark-version
  
  v0.5:
    group: benchmark-version
    env:
      MLC_MLPERF_INFERENCE_VERSION: v0.5

  performance-and-accuracy:
    default: true
    base:
    - all-modes
    default_variations:
      submission-generation-style: full
    group: submission-generation

  submission:
    base:
    - all-modes
    default_gui: true
    default_variations:
      submission-generation-style: full
    env:
      MLC_MLPERF_LOADGEN_COMPLIANCE: 'yes'
      MLC_MLPERF_SUBMISSION_RUN: 'yes'
      MLC_RUN_MLPERF_ACCURACY: 'on'
      MLC_RUN_SUBMISSION_CHECKER: 'yes'
      MLC_TAR_SUBMISSION_DIR: 'yes'
    group: submission-generation
    post_deps:
    - names:
      - submission-generator
      enable_if_env:
        MLC_MLPERF_SKIP_SUBMISSION_GENERATION:
        - 'no'
        - 'false'
        - 'False'
        - '0'
      tags: generate,mlperf,inference,submission
